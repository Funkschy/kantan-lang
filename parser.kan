// the 0 at the end is to enable the use of a semicolon at the end
#define LETCHECK(name, expr) let name = (expr); if (name) == null { return null; } 0
#define CONSUME_RET_NULL(ty) if !consume(p, (ty)) { return null; } 0
#define CONSUME_TOK_RET_NULL(name, ty) let name = l.empty_token(); \
    if !consume_token(p, (ty), &(name)) { return null; } 0

import "ast";
import "vec";
import "std";
import "mod";
import "span";
import "tyid";
import "func";
import "ident";
import "error";
import "ptrvec";
import "source";
import "record";
import "lexer" as l;
import "precedence" as prec;

type ParseError struct {
    span: span.Span,
    text: string
}

def empty_err(): ParseError {
    return ParseError { span: span.empty(), text: null };
}

def err_is_empty(err: *ParseError): bool {
    return err.text == null;
}

type Parser struct {
    in_panic_mode: bool,
    lexer: l.Lexer,
    errors: vec.Vec // vector of ParseErrors
}

def create(source: *source.SourceFile): Parser {
    return Parser {
        in_panic_mode: false,
        lexer: l.create(source),
        errors: vec.create(sizeof ParseError)
    };
}

def free_p(p: *Parser): void {
    free_errs_from(p, 0);
    p.errors.free();
}

def free_errs_from(p: *Parser, start: i32): void {
    let i = start;
    let elem = empty_err();
    while i < p.errors.len {
        p.errors.get(i, &elem as *void);
        delete elem.text;
        i = i + 1;
    }
    p.errors.len = p.errors.len - (p.errors.len - start);
}

def num_errs(p: *Parser): i32 {
    return p.errors.len;
}

def get_err(p: *Parser, idx: i32): *ParseError {
    return p.errors.get_ptr(idx) as *ParseError;
}

def push_err(p: *Parser, error: ParseError): void {
    p.errors.push(&error as *void);
}

// advances to the next token and saves the new token into dest
// dest: can be left empty if the result is to be ignored
// returns: true, if no error occured, false otherwise
def advance(p: *Parser, dest: *l.Token): bool {
    let next = l.next_token(&p.lexer);

    if next.ty == l.TokenType.EOF {
        if !p.in_panic_mode {
            let error = create_error(next.span, error.err2str(error.CompileError.UnexpectedEof));
            p.errors.push(&error as *void);
        }
        return false;
    } else if l.is_err(&next) && !p.in_panic_mode {
        // advance should not care about lex errors while in panic mode
        let error = create_lex_error(p, &next);
        push_err(p, error);
        if dest != null {
            *dest = next;
        }
        return false;
    }

    if dest != null {
        *dest = next;
    }

    return true;
}

def consume(p: *Parser, ty: l.TokenType): bool {
    return consume_token(p, ty, null);
}

def consume_ident(p: *Parser, ident: *l.Token): bool {
    if !consume_token(p, l.TokenType.Ident, ident) {
        return false;
    }

    return true;
}

def consume_token(p: *Parser, ty: l.TokenType, dest: *l.Token): bool {
    let next = l.empty_token();
    if !advance(p, &next) {
        if dest != null {
            *dest = next;
        }
        return false;
    }

    if dest != null {
        *dest = next;
    }

    if next.ty == ty {
        return true;
    }

    let error = create_consume_error(p, &next, ty);
    push_err(p, error);
    return false;
}

def consume_type_ident(p: *Parser, ident: *l.Token, err: *ParseError): bool {
    if !consume_token(p, l.TokenType.Ident, ident) {
        return false;
    }

    let dots = 0;
    while peek(p).ty == l.TokenType.Dot {
        consume(p, l.TokenType.Dot);

        let first_part = *ident;
        if !consume_token(p, l.TokenType.Ident, ident) {
            return false;
        }

        let merged_span = span.merge(first_part.span, ident.span);
        *ident = l.create_token_from_span(
            &p.lexer,
            l.TokenType.Ident,
            l.lexeme(&first_part),
            merged_span
        );
        dots = dots + 1;
    }

    if dots > 1 {
        *err = create_type_ident_error(
            p,
            ident.span,
            "type identifiers may not contain more than one '.'"
        );
        return false;
    }

    return true;
}

def consume_type(p: *Parser, dest: *tyid.Type): bool {
    let prev_num_errs = num_errs(p);

    let pointer_count = 0;
    while peek(p).ty == l.TokenType.Star {
        consume(p, l.TokenType.Star);
        pointer_count = pointer_count + 1;
    }

    let ty = l.empty_token();
    let illegal_type_err = empty_err();
    if !consume_type_ident(p, &ty, &illegal_type_err) {
        if num_errs(p) > prev_num_errs {
            free_errs_from(p, prev_num_errs);
            let error = create_consume_error_text(p, &ty, "type");
            push_err(p, error);
        }

        if !err_is_empty(&illegal_type_err) {
            push_err(p, illegal_type_err);
        }

        return false;
    }
    *dest = tyid.create_ptr(ident.create(ty), pointer_count);
    return true;
}

def peek(p: *Parser): l.Token {
    return l.peek(&p.lexer);
}

def parse(p: *Parser): *mod.Module {
    let src = l.source_file(&p.lexer);
    let curr_mod = new mod.create(src);

    while peek(p).ty != l.TokenType.EOF {
        let s = top_level(p);
        if s != null {
            mod.push_stmt(curr_mod, s);
        }
    }

    return curr_mod;
}

def top_level(p: *Parser): *ast.Stmt {
    let peek = peek(p);

    let prev_num_errs = num_errs(p);
    let start = l.current_ptr(&p.lexer);

    let s: *ast.Stmt = null;
    let consume_semi = false;

    if peek.ty == l.TokenType.Def {
        s = parse_func_def(p, false);
    } else if peek.ty == l.TokenType.Extern {
        consume(p, l.TokenType.Extern);
        s = parse_func_def(p, true);
        consume_semi = true;
    } else if peek.ty == l.TokenType.Type {
        s = parse_type_stmt(p);
    } else if peek.ty == l.TokenType.Import {
        s = parse_import_stmt(p);
        consume_semi = true;
    } else if peek.ty == l.TokenType.Let {
        s = parse_let_stmt(p);
        consume_semi = true;
    }

    if s == null {
        let end = sync(p);

        // no parse error was added...
        if prev_num_errs == num_errs(p) {
            // ... so just add a generic one
            let error = create_statement_error(p, start, end);
            push_err(p, error);
        }

        return null;
    }

    if consume_semi {
        if !consume(p, l.TokenType.Semi) {
            sync(p);
            ast.stmt_free(s);
            return null;
        }
    }

    return s;
}

def statement(p: *Parser): *ast.Stmt {
    let prev_num_errs = num_errs(p);
    let start = l.current_ptr(&p.lexer);

    let s = parse_statement(p);

    if s == null {
        let end = sync(p);

        // no parse error was added...
        if prev_num_errs == num_errs(p) {
            // ... so just add a generic one
            let error = create_statement_error(p, start, end);
            push_err(p, error);
        }

        return null;
    }

    return s;
}

def parse_statement(p: *Parser): *ast.Stmt {
    let peek = peek(p);

    if peek.ty == l.TokenType.If {
        return parse_if_stmt(p);
    }

    if peek.ty == l.TokenType.LBrace {
        return parse_block(p);
    }

    if peek.ty == l.TokenType.While {
        return parse_while_stmt(p);
    }

    if peek.ty == l.TokenType.For {
        return parse_for_stmt(p);
    }

    let simple = parse_simple_stmt(p);
    if simple != null && !consume(p, l.TokenType.Semi) {
        sync(p);
        ast.stmt_free(simple);
        return null;
    }

    return simple;
}

def parse_simple_stmt(p: *Parser): *ast.Stmt {
    let peek = peek(p);

    if peek.ty == l.TokenType.Let {
        return parse_let_stmt(p);
    }

    if peek.ty == l.TokenType.Delete {
        return parse_delete_stmt(p);
    }

    if peek.ty == l.TokenType.Return {
        return parse_return_stmt(p);
    }

    if peek.ty == l.TokenType.Continue {
        CONSUME_TOK_RET_NULL(continue_tok, l.TokenType.Continue);
        return ast.new_continue_stmt(continue_tok.span);
    }

    if peek.ty == l.TokenType.Break {
        CONSUME_TOK_RET_NULL(break_tok, l.TokenType.Break);
        return ast.new_break_stmt(break_tok.span);
    }

    let expr = expression(p, false);
    if expr == null {
        return null;
    }

    return ast.new_expr_stmt(expr);
}

def parse_delete_stmt(p: *Parser): *ast.Stmt {
    CONSUME_TOK_RET_NULL(del_tok, l.TokenType.Delete);

    LETCHECK(expr, expression(p, false));
    let del_span = span.merge(del_tok.span, expr.span);
    return ast.new_delete_stmt(del_span, expr);
}

def parse_return_stmt(p: *Parser): *ast.Stmt {
    CONSUME_TOK_RET_NULL(ret_tok, l.TokenType.Return);

    if peek(p).ty == l.TokenType.Semi {
        return ast.new_return_stmt(ret_tok.span, null);
    }

    LETCHECK(expr, expression(p, false));
    let ret_span = span.merge(ret_tok.span, expr.span);
    return ast.new_return_stmt(ret_span, expr);
}

def parse_import_stmt(p: *Parser): *ast.Stmt {
    CONSUME_TOK_RET_NULL(import_tok, l.TokenType.Import);

    let mod_path = l.empty_token();
    if !consume_token(p, l.TokenType.String, &mod_path) {
        return null;
    }

    let alias = ident.empty();
    if peek(p).ty == l.TokenType.As {
        let alias_tok = l.empty_token();
        if !consume(p, l.TokenType.As) || !consume_ident(p, &alias_tok) {
            return null;
        }
        alias = ident.create(alias_tok);
    }

    let import_span = span.merge(import_tok.span, mod_path.span);
    return ast.new_import_stmt(import_span, ident.create(mod_path), alias);
}

def parse_let_stmt(p: *Parser): *ast.Stmt {
    CONSUME_TOK_RET_NULL(let_tok, l.TokenType.Let);

    let ident = l.empty_token();
    if !consume_ident(p, &ident) {
        return null;
    }

    let ty = tyid.empty();
    if peek(p).ty == l.TokenType.Colon {
        CONSUME_RET_NULL(l.TokenType.Colon);
        if !consume_type(p, &ty) {
            return null;
        }
    }

    CONSUME_RET_NULL(l.TokenType.Eq);

    let e = expression(p, false);
    if e == null {
        return null;
    }

    let let_span = span.merge(let_tok.span, e.span);
    return ast.new_let_stmt(let_span, ident, ty, e);
}
import "io";
def parse_type_stmt(p: *Parser): *ast.Stmt {
    CONSUME_TOK_RET_NULL(type_tok, l.TokenType.Type);

    let ident_token = l.empty_token();
    if !consume_ident(p, &ident_token) {
        return null;
    }

    if peek(p).ty == l.TokenType.Enum {
        return parse_enum_decl(p, ident_token, type_tok);
    }

    return parse_struct_decl(p, ident_token, type_tok);
}

def parse_struct_decl(p: *Parser, ident_token: l.Token, type_tok: l.Token): *ast.Stmt {
    CONSUME_RET_NULL(l.TokenType.Struct);
    CONSUME_RET_NULL(l.TokenType.LBrace);

    let closing_brace = l.empty_token();
    let fields = parse_field_list(p, &closing_brace);
    if closing_brace.ty == l.TokenType.UnknownErr {
        fields.free();
        return null;
    }

    let struct_span = span.merge(type_tok.span, closing_brace.span);
    return ast.new_struct_decl_stmt(
        struct_span,
        ident.create(ident_token),
        fields
    );
}

def parse_enum_decl(p: *Parser, ident_token: l.Token, type_tok: l.Token): *ast.Stmt {
    CONSUME_RET_NULL(l.TokenType.Enum);
    CONSUME_RET_NULL(l.TokenType.LBrace);

    let closing_brace = l.empty_token();
    let start_value: *ast.Expr = null;
    let values = parse_enum_values(p, &closing_brace, &start_value);
    if closing_brace.ty == l.TokenType.UnknownErr {
        values.free();
        ast.expr_free(start_value);
        return null;
    }

    let enum_span = span.merge(type_tok.span, closing_brace.span);
    return ast.new_enum_decl_stmt(
        enum_span,
        ident.create(ident_token),
        values,
        start_value
    );
}

def parse_func_def(p: *Parser, is_extern: bool): *ast.Stmt {
    CONSUME_TOK_RET_NULL(def_tok, l.TokenType.Def);

    let has_receiver = false;
    let receiver: func.Param = undefined;

    // Receivers are only allow on non extern functions
    if peek(p).ty == l.TokenType.LParen && !is_extern {
        CONSUME_TOK_RET_NULL(l_paren, l.TokenType.LParen);
        let closing_paren = l.empty_token();
        // don't allow varargs as receivers
        let receiver_list = parse_param_list(p, &closing_paren, false);

        // a parse error has occured during param parsing
        if closing_paren.ty == l.TokenType.UnknownErr {
            return null;
        }

        // There can only be one receiver param
        if receiver_list.len != 1 {
            receiver_list.free();
            let error = create_invalid_recv_count_error(p, &l_paren, receiver_list.len);
            push_err(p, error);
            return null;
        }

        receiver = *(receiver_list.get_ptr(0) as *func.Param);
        has_receiver = true;
        receiver_list.free();
    }

    let ident = l.empty_token();
    if !consume_ident(p, &ident) {
        return null;
    }

    CONSUME_TOK_RET_NULL(l_paren, l.TokenType.LParen);
    let closing_paren = l.empty_token();
    let params = parse_param_list(p, &closing_paren, is_extern);
    // a parse error has occured during param parsing
    if closing_paren.ty == l.TokenType.UnknownErr {
        return null;
    }

    let param_list = func.pl_from_vec(params);
    let end_span = closing_paren.span;
    let ret_ty = tyid.empty();

    if peek(p).ty == l.TokenType.Colon {
        if !consume(p, l.TokenType.Colon) {
            func.free_pl(&param_list);
            return null;
        }

        if !consume_type(p, &ret_ty) {
            func.free_pl(&param_list);
            return null;
        }

        end_span = tyid.ident_span(&ret_ty);
    }

    let block: *ast.Stmt = null;
    if !is_extern {
        block = parse_block(p);
        if block == null {
            func.free_pl(&param_list);
            return null;
        }
        end_span = block.span;
    }

    let func_span = span.merge(def_tok.span, end_span);

    if has_receiver {
        return ast.new_method_decl_stmt(
            func_span,
            ident,
            receiver,
            param_list,
            ret_ty,
            is_extern,
            ast.as_block_stmt(block)
        );
    }

    return ast.new_func_decl_stmt(
        func_span,
        ident,
        param_list,
        ret_ty,
        is_extern,
        ast.as_block_stmt(block)
    );
}

def parse_while_stmt(p: *Parser): *ast.Stmt {
    CONSUME_TOK_RET_NULL(while_tok, l.TokenType.While);

    let peeked = peek(p);
    let condition = expression(p, true);

    if condition == null {
        let error = create_consume_error_text(p, &peeked, "condition");
        push_err(p, error);
        return null;
    }

    let block = parse_block(p);
    if block == null {
        ast.expr_free(condition);
        return null;
    }

    let while_span = span.merge(while_tok.span, block.span);
    return ast.new_while_stmt(while_span, condition, ast.as_block_stmt(block));
}

def parse_for_stmt(p: *Parser): *ast.Stmt {
    CONSUME_TOK_RET_NULL(for_tok, l.TokenType.For);

    let initializer: *ast.Stmt = null;
    if peek(p).ty != l.TokenType.Semi {
        initializer = parse_simple_stmt(p);
        if initializer == null {
            return null;
        }
    }

    CONSUME_RET_NULL(l.TokenType.Semi);

    let peeked = peek(p);
    let condition = expression(p, false);
    if condition == null {
        let error = create_consume_error_text(p, &peeked, "condition");
        push_err(p, error);
        ast.stmt_free(initializer);
        return null;
    }

    CONSUME_RET_NULL(l.TokenType.Semi);

    let increment: *ast.Stmt = null;
    if peek(p).ty != l.TokenType.LBrace {
        let inc_expr = expression(p, true);
        if inc_expr == null {
            ast.stmt_free(initializer);
            ast.expr_free(condition);
            return null;
        }
        increment = ast.new_expr_stmt(inc_expr);
    }

    let block = parse_block(p);
    if block == null {
        ast.stmt_free(initializer);
        ast.expr_free(condition);
        ast.stmt_free(increment);
        return null;
    }

    let for_span = span.merge(for_tok.span, block.span);
    return ast.new_for_stmt(
        for_span,
        initializer,
        condition,
        increment,
        ast.as_block_stmt(block)
    );
}

def parse_if_stmt(p: *Parser): *ast.Stmt {
    CONSUME_TOK_RET_NULL(if_tok, l.TokenType.If);

    let peeked = peek(p);
    let condition = expression(p, true);

    if condition == null {
        let error = create_consume_error_text(p, &peeked, "condition");
        push_err(p, error);
        return null;
    }

    let block = parse_block(p);
    if block == null {
        ast.expr_free(condition);
        return null;
    }

    let if_span = span.merge(if_tok.span, block.span);
    let if_stmt = ast.new_if_stmt(if_span, condition, ast.as_block_stmt(block), null);
    if peek(p).ty != l.TokenType.Else {
        return if_stmt;
    }
    consume(p, l.TokenType.Else);

    let else_stmt: *ast.Stmt = null;
    let peeked = peek(p);
    if peeked.ty == l.TokenType.If {
        else_stmt = parse_if_stmt(p);
    } else if peeked.ty == l.TokenType.LBrace {
        else_stmt = parse_block(p);
    } else {
        let error = create_consume_error_text(p, &peeked, "either 'if' or '{' after else");
        push_err(p, error);
    }

    if else_stmt == null {
        ast.stmt_free(if_stmt);
        return null;
    }

    let complete_span = span.merge(if_span, else_stmt.span);

    ast.as_if_stmt(if_stmt).else_stmt = else_stmt;
    if_stmt.span = complete_span;

    return if_stmt;
}

def free_statements(statements: *ptrvec.Vec): void {
    let i = 0;
    while i < statements.len {
        let s = statements.get(i) as *ast.Stmt;
        ast.stmt_free(s);
        i = i + 1;
    }

    statements.free();
}

def parse_block(p: *Parser): *ast.Stmt {
    CONSUME_TOK_RET_NULL(open_brace_tok, l.TokenType.LBrace);
    let statements = ptrvec.create();
    let had_error = false;

    let peeked = peek(p);
    while peeked.ty != l.TokenType.EOF && peeked.ty != l.TokenType.RBrace {
        let s = statement(p);
        if s == null {
            sync(p);
            had_error = true;
        } else {
            statements.push_ptr(s as *void);
        }

        peeked = peek(p);
    }

    if had_error {
        free_statements(&statements);
        return null;
    }

    let closing_brace = l.empty_token();
    if !consume_token(p, l.TokenType.RBrace, &closing_brace) {
        free_statements(&statements);
        return null;
    }

    let block_span = span.merge(open_brace_tok.span, closing_brace.span);
    return ast.new_block_stmt(block_span, statements);
}

def parse_field_list(p: *Parser, closing_brace: *l.Token): vec.Vec {
#define FAIL() fields.free(); return vec.create(0)

    let fields = vec.create(sizeof record.Field);

    let peeked = peek(p);
    while peeked.ty != l.TokenType.EOF && peeked.ty != l.TokenType.RBrace {
        let ident_token = l.empty_token();
        if !consume_ident(p, &ident_token) {
            FAIL();
        }
        let ident = ident.create(ident_token);

        if !consume(p, l.TokenType.Colon) {
            FAIL();
        }

        let ty = tyid.empty();
        if !consume_type(p, &ty) {
            FAIL();
        }

        let field = record.create_field(ident, ty);
        fields.push(&field as *void);

        peeked = peek(p);

        // consume separator
        if peeked.ty == l.TokenType.Comma {
            consume(p, l.TokenType.Comma);
        }
    }

    if !consume_token(p, l.TokenType.RBrace, closing_brace) {
        FAIL();
    }

    return fields;

#undef FAIL
}

def parse_enum_values(p: *Parser, closing_brace: *l.Token, start_value: **ast.Expr): vec.Vec {
#define FAIL() values.free(); return vec.create(0)

    let values = vec.create(sizeof ident.Ident);

    let peeked = peek(p);
    while peeked.ty != l.TokenType.EOF && peeked.ty != l.TokenType.RBrace {
        let ident_token = l.empty_token();
        if !consume_ident(p, &ident_token) {
            FAIL();
        }
        let ident = ident.create(ident_token);

        // The first enum value can be followed by a starting value
        if values.len == 0 && peek(p).ty == l.TokenType.Eq {
            consume(p, l.TokenType.Eq);
            *start_value = parse_expression(p, prec.Precedence.Assign, false);

            if *start_value == null {
                FAIL();
            }
        }

        values.push(&ident as *void);

        peeked = peek(p);

        // consume separator
        if peek(p).ty != l.TokenType.RBrace && !consume(p, l.TokenType.Comma) {
            FAIL();
        }
    }

    if !consume_token(p, l.TokenType.RBrace, closing_brace) {
        FAIL();
    }

    return values;

#undef FAIL
}

def parse_param_list(p: *Parser, closing_paren: *l.Token, allow_va: bool): vec.Vec {
#define FAIL() params.free(); return vec.create(0)

    let params = vec.create(sizeof func.Param);

    let peeked = peek(p);
    while peeked.ty != l.TokenType.EOF && peeked.ty != l.TokenType.RParen {
        let ident_token = l.empty_token();
        let ty = tyid.empty();

        if allow_va && peek(p).ty == l.TokenType.TripleDot {
            consume_token(p, l.TokenType.TripleDot, &ident_token);
        } else {
            ident_token = l.empty_token();
            if !consume_ident(p, &ident_token) {
                FAIL();
            }

            if !consume(p, l.TokenType.Colon) {
                FAIL();
            }

            if !consume_type(p, &ty) {
                FAIL();
            }
        }

        let ident = ident.create(ident_token);
        let param = func.create_param(ident, ty);
        params.push(&param as *void);

        peeked = peek(p);

        // consume separator
        if peeked.ty == l.TokenType.Comma {
            consume(p, l.TokenType.Comma);
        }
    }

    if !consume_token(p, l.TokenType.RParen, closing_paren) {
        FAIL();
    }

    return params;

#undef FAIL
}

// returns false on error
def parse_arg_list(p: *Parser, out: *ast.ArgList): bool {
#define FAIL() ast.free_al(&args); return false
    let args = ast.create_arg_list();

    let peeked = peek(p);
    while peeked.ty != l.TokenType.EOF && peeked.ty != l.TokenType.RParen {
        let arg = expression(p, false);
        if arg == null {
            FAIL();
        }
        ast.push_arg(&args, arg);

        peeked = peek(p);

        if peeked.ty != l.TokenType.RParen {
            if !consume(p, l.TokenType.Comma) {
                FAIL();
            }
        }
    }

    *out = args;
    return true;
#undef FAIL
}

// TODO(#24): allow trailing commas
def parse_init_list(p: *Parser, closing_brace: *l.Token): ast.InitList {
#define FAIL() ast.free_il(&inits); return ast.create_init_list()
    let inits = ast.create_init_list();

    let peeked = peek(p);
    while peeked.ty != l.TokenType.EOF && peeked.ty != l.TokenType.RBrace {
        let ident_token = l.empty_token();
        if !consume_ident(p, &ident_token) {
            FAIL();
        }

        if !consume(p, l.TokenType.Colon) {
            FAIL();
        }

        let val = expression(p, false);
        if val == null {
            FAIL();
        }

        let init = ast.create_init(ident.create(ident_token), val);
        ast.push_init(&inits, init);

        peeked = peek(p);

        if peeked.ty != l.TokenType.RBrace {
            if !consume(p, l.TokenType.Comma) {
                FAIL();
            }
        }
    }

    if !consume_token(p, l.TokenType.RBrace, closing_brace) {
        FAIL();
    }

    return inits;
#undef FAIL
}

def expression(p: *Parser, no_struct: bool): *ast.Expr {
    LETCHECK(left, parse_expression(p, prec.Precedence.Assign, no_struct));
    while l.is_assign(peek(p).ty) {
        let assign_type: l.Token = undefined;
        advance(p, &assign_type);
        let value = expression(p, no_struct);
        if value == null {
            ast.expr_free(left);
            return null;
        }
        let merged_span = span.merge(left.span, value.span);
        left = ast.new_assign_expr(merged_span, assign_type, left, value);
    }

    return left;
}

def parse_expression(p: *Parser, precedence: prec.Precedence, no_struct: bool): *ast.Expr {
    LETCHECK(left, prefix(p, no_struct));

    while next_higher_precedence(p, precedence, no_struct) {
        let token = l.empty_token();
        if !advance(p, &token) {
            ast.expr_free(left);
            return null;
        }

        let infix = infix(p, &token, left, no_struct);
        if infix == null {
            ast.expr_free(left);
            return null;
        }

        left = infix;
    }

    return left;
}

def next_higher_precedence(p: *Parser, current: prec.Precedence, no_struct: bool): bool {
    let t = peek(p);

    if l.is_err(&t) || t.ty == l.TokenType.EOF {
        return false;
    }

    if t.ty == l.TokenType.LBrace {
        return !no_struct && prec.get(t.ty) > current;
    }

    return prec.get(t.ty) > current;
}

def prefix(p: *Parser, no_struct: bool): *ast.Expr {
#define UNARY(tok, unary_ty) if token.ty == (tok) { \
        LETCHECK(expr, parse_expression(p, prec.Precedence.Unary, no_struct)); \
        let merged_span = span.merge(token.span, expr.span); \
        return ast.new_unary_expr(merged_span, (unary_ty), expr); \
    } 0

    let token = l.empty_token();
    if !advance(p, &token) {
        return null;
    }

    if token.ty == l.TokenType.Int {
        return ast.new_int_expr(token.span, l.lexeme(&token));
    }

    if token.ty == l.TokenType.Float {
        return ast.new_float_expr(token.span, l.lexeme(&token));
    }

    if token.ty == l.TokenType.String {
        return ast.new_string_expr(token.span);
    }

    if token.ty == l.TokenType.Char {
        return ast.new_char_expr(token.span, l.lexeme(&token));
    }

    if token.ty == l.TokenType.Ident {
        return ast.new_ident_expr(token);
    }

    if token.ty == l.TokenType.Null {
        return ast.new_null_expr(token.span);
    }

    if token.ty == l.TokenType.Undefined {
        return ast.new_undefined_expr(token.span);
    }

    if token.ty == l.TokenType.Sizeof {
        let ty = tyid.empty();
        if !consume_type(p, &ty) {
            return null;
        }

        let merged_span = span.merge(token.span, tyid.ident_span(&ty));
        return ast.new_sizeof_expr(merged_span, ty);
    }

    if token.ty == l.TokenType.New {
        LETCHECK(e, expression(p, no_struct));
        let merged_span = span.merge(token.span, e.span);
        return ast.new_new_expr(merged_span, e);
    }

    UNARY(l.TokenType.Ampersand, ast.UnaryKind.Ref);
    UNARY(l.TokenType.Star, ast.UnaryKind.Deref);
    UNARY(l.TokenType.Bang, ast.UnaryKind.NegBool);
    UNARY(l.TokenType.Minus, ast.UnaryKind.NegNum);

    if token.ty == l.TokenType.LParen {
        // ignore no_struct, because it's in parens
        LETCHECK(e, expression(p, false));

        if !consume(p, l.TokenType.RParen) {
            ast.expr_free(e);
            return null;
        }

        return e;
    }

    return null;
#undef UNARY
}

def infix(p: *Parser, token: *l.Token, left: *ast.Expr, no_struct: bool): *ast.Expr {
    // access expr
    if token.ty == l.TokenType.Dot {
        let right = l.empty_token();
        if !consume_ident(p, &right) {
            return null;
        }

        let right = ast.new_ident_expr(right);
        let merged_span = span.merge(left.span, right.span);
        return ast.new_access_expr(merged_span, left, ast.as_ident_expr(right));
    }

    // call expr
    if token.ty == l.TokenType.LParen {
        let args = ast.create_arg_list();
        if !parse_arg_list(p, &args) {
            return null;
        }

        let closing_paren = l.empty_token();
        if !consume_token(p, l.TokenType.RParen, &closing_paren) {
            ast.free_al(&args);
            return null;
        }

        let merged_span = span.merge(left.span, closing_paren.span);
        return ast.new_call_expr(merged_span, left, args);
    }

    // init expr
    if token.ty == l.TokenType.LBrace {
        let closing_brace = l.empty_token();
        let inits = parse_init_list(p, &closing_brace);

        if closing_brace.ty == l.TokenType.UnknownErr {
            return null;
        }

        let merged_span = span.merge(left.span, closing_brace.span);
        return ast.new_init_expr(merged_span, left, inits);
    }

    if token.ty == l.TokenType.As {
        let ty = tyid.empty();
        if !consume_type(p, &ty) {
            return null;
        }

        let merged_span = span.merge(left.span, tyid.ident_span(&ty));
        return ast.new_as_expr(merged_span, left, ty);
    }

    // binary expression

    let found = false;
    let ty: ast.BinaryKind = undefined;

    if token.ty == l.TokenType.Plus {
        found = true;
        ty = ast.BinaryKind.Add;
    } else if token.ty == l.TokenType.Minus {
        found = true;
        ty = ast.BinaryKind.Sub;
    } else if token.ty == l.TokenType.Star {
        found = true;
        ty = ast.BinaryKind.Mul;
    } else if token.ty == l.TokenType.Slash {
        found = true;
        ty = ast.BinaryKind.Div;
    } else if token.ty == l.TokenType.Percent {
        found = true;
        ty = ast.BinaryKind.Mod;
    } else if token.ty == l.TokenType.Smaller {
        found = true;
        ty = ast.BinaryKind.ST;
    } else if token.ty == l.TokenType.SmallerEq {
        found = true;
        ty = ast.BinaryKind.SE;
    } else if token.ty == l.TokenType.Greater {
        found = true;
        ty = ast.BinaryKind.GT;
    } else if token.ty == l.TokenType.GreaterEq {
        found = true;
        ty = ast.BinaryKind.GE;
    } else if token.ty == l.TokenType.DoubleAmpersand {
        found = true;
        ty = ast.BinaryKind.LogAnd;
    } else if token.ty == l.TokenType.DoublePipe {
        found = true;
        ty = ast.BinaryKind.LogOr;
    } else if token.ty == l.TokenType.DoubleEq {
        found = true;
        ty = ast.BinaryKind.Eq;
    } else if token.ty == l.TokenType.BangEq {
        found = true;
        ty = ast.BinaryKind.NE;
    } else if token.ty == l.TokenType.SmallerSmaller {
        found = true;
        ty = ast.BinaryKind.LShift;
    } else if token.ty == l.TokenType.GreaterGreater {
        found = true;
        ty = ast.BinaryKind.RShift;
    }

    // a pattern matched
    if found {
        let prec = prec.get(token.ty);
        LETCHECK(right, parse_expression(p, prec, no_struct));
        let merged_span = span.merge(left.span, right.span);
        return ast.new_binary_expr(merged_span, ty, token.span, left, right);
    }

    return null;
}

def sync(p: *Parser): string {
    p.in_panic_mode = true;
    let pos = inner_sync(p);
    p.in_panic_mode = false;
    return pos;
}

// should only be called by sync function
def inner_sync(p: *Parser): string {
    let previous = l.empty_token();
    if !advance(p, &previous) {
        return source.code(p.lexer.source) + l.end_pos(&p.lexer);
    }

    let peeked = peek(p);
    while peeked.ty != l.TokenType.EOF {
        let merged_span = previous.span;
        let pos = merged_span.start;
        if previous.ty == l.TokenType.Semi && peek(p).ty != l.TokenType.RBrace {
            return pos;
        }

        if peeked.ty == l.TokenType.Let || peeked.ty == l.TokenType.Def {
            return pos;
        }

        if !advance(p, &previous) {
            return pos;
        }

        if previous.ty == l.TokenType.RBrace {
            return previous.span.start;
        }

        peeked = peek(p);
    }

    return previous.span.start;
}

def create_error(span: span.Span, text: string): ParseError {
    return ParseError { span: span, text: text };
}

def create_type_ident_error(p: *Parser, err_span: span.Span, reason: string): ParseError {
    let len = span.len(err_span);
    return create_error(
        err_span,
        error.err2str(error.CompileError.InvalidTypeIdent, len, err_span.start, reason)
    );
}

def create_statement_error(p: *Parser, start: string, end: string): ParseError {
    let err_span = span.create(start, end);

    return create_error(
        err_span,
        error.err2str(error.CompileError.CouldNotParseStmt)
    );
}

def create_invalid_recv_count_error(p: *Parser, l_paren: *l.Token, count: i32): ParseError {
    return create_error(
        l_paren.span,
        error.err2str(error.CompileError.InvalidReceiverCount, count)
    );
}

def create_lex_error(p: *Parser, next: *l.Token): ParseError {
    // len for lexeme
    let len = l.token_len(next);
    let err_ty = error.CompileError.UnknownSymbol;

    if next.ty == l.TokenType.CharErr {
        err_ty = error.CompileError.CharLitLen;
    }

    if next.ty == l.TokenType.EscapeErr {
        err_ty = error.CompileError.InvalidEscapeSequence;
    }

    return create_error(
        next.span,
        error.err2str(err_ty, len, l.lexeme(next))
    );
}

def create_consume_error(p: *Parser, peeked: *l.Token, expected_ty: l.TokenType): ParseError {
    return create_consume_error_text(
        p,
        peeked,
        l.token_ty_to_static_string(expected_ty)
    );
}

def create_consume_error_text(p: *Parser, peeked: *l.Token, text: string): ParseError {
    let peek_str: string = null;
    let needs_free = l.token_to_string(peeked, &peek_str);

    let err_str = error.err2str(
        error.CompileError.ExpectedButGot,
        text,
        peek_str
    );

    if needs_free {
        delete peek_str;
    }

    return create_error(peeked.span, err_str);
}
