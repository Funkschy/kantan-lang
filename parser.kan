#include "token_types.h"
#include "expr_types.h"
#include "std.h"

import "lexer"
import "ast"
import "precedence"
import "span"
import "io" // TODO: only debug

type Parser struct {
    lexer: lexer.Lexer
}

def create(source: string, span_interner: *span.SpanInterner, ctx: i32): Parser {
    return Parser { lexer: lexer.create(source, span_interner, ctx) };
}

def advance(p: *Parser): lexer.Token {
    return lexer.next_token(&p.lexer);
}

def consume(p: *Parser, ty: i32): bool {
    if peek(p).ty == ty {
        advance(p);
        return true;
    }

    return false;
}

def peek(p: *Parser): lexer.Token {
    return lexer.peek(&p.lexer);
}

def parse(p: *Parser): ast.CompilationUnit {
    let cu = ast.cu_create();

    while peek(p).ty != TOKEN_EOF {
        let s = statement(p);
        if !consume(p, TOKEN_SEMI) {
            ast.stmt_free(s);
            return cu;
        }
        ast.cu_push(&cu, s);
    }

    return cu;
}

def statement(p: *Parser): *ast.Stmt {
    return ast.make_expr_stmt(expression(p));
}

def expression(p: *Parser): *ast.Expr {
    return parse_expression(p, precedence.assign());
}

def parse_expression(p: *Parser, precedence: i32): *ast.Expr {
    letcheck(left, prefix(p));

    while next_higher_precedence(p, precedence) {
        let token = advance(p);

        let infix = infix(p, &token, left);
        if infix == null {
            delete left;
            return null;
        }

        left = infix;
    }

    return left;
}

def next_higher_precedence(p: *Parser, precedence: i32): bool {
    let t = peek(p);

    if t.ty == TOKEN_ERR || t.ty == TOKEN_EOF {
        return false;
    }

    return precedence.get(t.ty) > precedence;
}

def prefix(p: *Parser): *ast.Expr {
    let token = advance(p);

    if token.ty == TOKEN_INT {
        let len = span.get(p.lexer.span_interner, token.span).len;
        return ast.make_int(token.span, len, token.lexeme);
    } else if token.ty == TOKEN_LPAREN {
        let e = expression(p);

        if !consume(p, TOKEN_RPAREN) {
            ast.expr_free(e);
            return null;
        }

        // TODO: this can over/underflow. Needs to be checked for interning
        e.span.start = e.span.start - 1;
        e.span.len_or_tag = e.span.len_or_tag + 2;

        return e;
    }

    return null;
}

def infix(p: *Parser, token: *lexer.Token, left: *ast.Expr): *ast.Expr {
    let found = false;
    let ty = 0;

    if token.ty == TOKEN_PLUS {
        found = true;
        ty = BINARY_ADD;
    } else if token.ty == TOKEN_MINUS {
        found = true;
        ty = BINARY_SUB;
    } else if token.ty == TOKEN_STAR {
        found = true;
        ty = BINARY_MUL;
    } else if token.ty == TOKEN_SLASH {
        found = true;
        ty = BINARY_DIV;
    }

    // a pattern matched
    if found {
        let prec = precedence.get(token.ty);
        letcheck(right, parse_expression(p, prec));
        let span = span.merge(p.lexer.span_interner, left.span, right.span);
        return ast.make_binary(span, ty, left, right);
    }

    return null;
}
