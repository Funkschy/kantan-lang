#include "./token_types.h"
#include "./expr_types.h"
#include "./error_code.h"
#include "./std.h"

import "lexer"
import "ast"
import "precedence"
import "span"
import "vec"
import "std"

import "io" // TODO: only debug

type ParseError struct {
    span: span.Span,
    text: string
}

type Parser struct {
    lexer: lexer.Lexer,
    errors: vec.Vec // vector of ParseErrors
}

def create(source: string, span_interner: *span.SpanInterner, ctx: i32): Parser {
    return Parser {
        lexer: lexer.create(source, span_interner, ctx),
        errors: vec.create(sizeof ParseError)
    };
}

def free_p(p: *Parser): void {
    let i = 0;
    let elem = ParseError { span: span.empty(), text: null };
    while i < p.errors.len {
        vec.get(&p.errors, i, &elem as *void);
        delete elem.text;
        i = i + 1;
    }

    vec.free_v(&p.errors);
}

def get_err(p: *Parser, idx: i32, dest: *ParseError): bool {
    return vec.get(&p.errors, idx, dest as *void);
}

def advance(p: *Parser): lexer.Token {
    let next = lexer.next_token(&p.lexer);

    if next.ty == TOKEN_EOF {
        let error = ParseError { span: next.span, text: std.err2str(ERROR_UNEXPECTED_EOF) };
        vec.push(&p.errors, &error as *void);
    } else if next.ty == TOKEN_ERR {
        // len for lexeme
        let len = span.get(p.lexer.span_interner, next.span).len;

        let error = ParseError {
            span: next.span,
            text: std.err2str(ERROR_UNKNOWN_SYMBOL, len, next.lexeme)
        };
        vec.push(&p.errors, &error as *void);
    }

    return next;
}

def consume(p: *Parser, ty: i32): bool {
    let peek = peek(p);
    if peek.ty == ty {
        advance(p);
        return true;
    }

    let err_str = std.err2str(
        ERROR_EXPECTED_BUT_GOT,
        lexer.token_ty_to_string(ty),
        lexer.token_to_string(&peek)
    );

    let error = ParseError { span: peek.span, text: err_str };
    vec.push(&p.errors, &error as *void);
    return false;
}

def peek(p: *Parser): lexer.Token {
    return lexer.peek(&p.lexer);
}

def parse(p: *Parser): ast.CompilationUnit {
    let cu = ast.cu_create();

    while peek(p).ty != TOKEN_EOF {
        let s = statement(p);
        if !consume(p, TOKEN_SEMI) {
            if s != null {
                ast.stmt_free(s);
            }
            return cu;
        }
        if s != null {
            ast.cu_push(&cu, s);
        }
    }

    return cu;
}

def statement(p: *Parser): *ast.Stmt {
    letcheck(expr, expression(p));
    return ast.make_expr_stmt(expr);
}

def expression(p: *Parser): *ast.Expr {
    return parse_expression(p, precedence.assign());
}

def parse_expression(p: *Parser, precedence: i32): *ast.Expr {
    letcheck(left, prefix(p));

    while next_higher_precedence(p, precedence) {
        let token = advance(p);

        let infix = infix(p, &token, left);
        if infix == null {
            delete left;
            return null;
        }

        left = infix;
    }

    return left;
}

def next_higher_precedence(p: *Parser, precedence: i32): bool {
    let t = peek(p);

    if t.ty == TOKEN_ERR || t.ty == TOKEN_EOF {
        return false;
    }

    return precedence.get(t.ty) > precedence;
}

def prefix(p: *Parser): *ast.Expr {
    let token = advance(p);

    if token.ty == TOKEN_INT {
        let len = span.get(p.lexer.span_interner, token.span).len;
        return ast.make_int(token.span, len, token.lexeme);
    } else if token.ty == TOKEN_LPAREN {
        letcheck(e, expression(p));

        if !consume(p, TOKEN_RPAREN) {
            ast.expr_free(e);
            return null;
        }

        // TODO: this can over/underflow. Needs to be checked for interning
        e.span.start = e.span.start - 1;
        e.span.len_or_tag = e.span.len_or_tag + 2;

        return e;
    }

    return null;
}

def infix(p: *Parser, token: *lexer.Token, left: *ast.Expr): *ast.Expr {
    let found = false;
    let ty = 0;

    if token.ty == TOKEN_PLUS {
        found = true;
        ty = BINARY_ADD;
    } else if token.ty == TOKEN_MINUS {
        found = true;
        ty = BINARY_SUB;
    } else if token.ty == TOKEN_STAR {
        found = true;
        ty = BINARY_MUL;
    } else if token.ty == TOKEN_SLASH {
        found = true;
        ty = BINARY_DIV;
    }

    // a pattern matched
    if found {
        let prec = precedence.get(token.ty);
        letcheck(right, parse_expression(p, prec));
        let span = span.merge(p.lexer.span_interner, left.span, right.span);
        return ast.make_binary(span, ty, left, right);
    }

    return null;
}
